{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williamkho-xzq/text-as-data/blob/main/Lab_4_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text as Data Lab 4: Text Classification\n",
        "\n",
        "The goal of this lab is to build a classifier that can identify research articles that discuss clinical trials. You'll then tune and evaluate it.\n",
        "\n",
        "[Clinical trials](https://en.wikipedia.org/wiki/Clinical_trial) test out new treatments for diseases and their results are generally reported in published research articles. Keeping track of all the results of clinical trials is very important but can be challenging. We'll be looking at the titles and abstracts of these articles. Some authors do a good job of linking them back to registered clinical trials and some do not. Identifying that a paper is talking about a clinical trial is an important step towards gathering all these results together for further analysis.\n",
        "\n",
        "**Before you start, save a copy of this lab to your drive using \"File > Save a Copy in Drive\".** If you skip this step, you may lose progress that you have made (e.g., if you close the browser tab or your computer crashes).\n",
        "\n",
        "This lab is linked with the fourth lecture. Please watch the lecture and refer to the slides as needed.\n",
        "\n",
        "In this lab you will learn about:\n",
        "- Splitting a dataset into training, validation and test sets\n",
        "- Building a classifier for a binary classification problem\n",
        "- Evaluation metrics for classification\n",
        "- Tuning a classifier with a validation set\n",
        "- Using the test set for final evaluations\n",
        "\n",
        "This lab will make use of [scikit-learn](https://scikit-learn.org). This lab won't give you the code directly but will point you towards the documentation for the function to use. **Each scikit-learn function comes with example code in its documentation.** You should examine the example code there and follow any extra instructions for the lab. The lab also does not use `labtest` this time but will provide expected answers."
      ],
      "metadata": {
        "id": "PKluMul19CYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the text classification data\n",
        "\n",
        "We'll be looking at the problem of identifying if a biomedical research article is discussing the results of a [clinical trial](https://en.wikipedia.org/wiki/Clinical_trial). Biomedical research articles are indexed in a huge database called [PubMed](https://pubmed.ncbi.nlm.nih.gov/). It tracks the titles & abstracts of almost all biomedical publications along with various other bits of metadata.\n",
        "\n",
        "We've created a small subset of these articles that focus on [asthma](https://en.wikipedia.org/wiki/Asthma). Some of the articles are reporting on clinical trials and others are not.\n",
        "\n",
        "Let's download it:"
      ],
      "metadata": {
        "id": "na9QqFaf9SN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O asthma_dataset.json https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/ERJRy93FbypJm4mawO79wwgB1bt9uvuvHQs5gtKRkzXyHg?download=1"
      ],
      "metadata": {
        "id": "CTVB3fVFkFdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3623cd0c-0431-4003-eaf3-b3adc5837c74"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-06 14:34:44--  https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/ERJRy93FbypJm4mawO79wwgB1bt9uvuvHQs5gtKRkzXyHg?download=1\n",
            "Resolving gla-my.sharepoint.com (gla-my.sharepoint.com)... 13.107.136.10, 13.107.138.10, 2a01:111:f402:f0fa::53\n",
            "Connecting to gla-my.sharepoint.com (gla-my.sharepoint.com)|13.107.136.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/_layouts/15/download.aspx?UniqueId=ddcb51126fc5492a9b899ac0eefdc308 [following]\n",
            "--2024-02-06 14:34:45--  https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/_layouts/15/download.aspx?UniqueId=ddcb51126fc5492a9b899ac0eefdc308\n",
            "Reusing existing connection to gla-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1675650 (1.6M) [application/json]\n",
            "Saving to: ‘asthma_dataset.json’\n",
            "\n",
            "asthma_dataset.json 100%[===================>]   1.60M  2.03MB/s    in 0.8s    \n",
            "\n",
            "2024-02-06 14:34:46 (2.03 MB/s) - ‘asthma_dataset.json’ saved [1675650/1675650]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's a JSON file. We can use the Unix `head` command to look inside the file. As the file is nicely formatted, we can see that it is a set of records with four fields: `is_clinical_trial`, `pubmed_id`, `title` and `abstract`."
      ],
      "metadata": {
        "id": "X_CmIQOJBBSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head asthma_dataset.json"
      ],
      "metadata": {
        "id": "3F7YxdM-kPx6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53f052c-d684-49f4-a389-82d277ae0a9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"is_clinical_trial\": true,\n",
            "    \"pubmed_id\": 346628,\n",
            "    \"title\": \"Immunotherapy in cat-induced asthma. Double-blind trial with evaluation of bronchial responses to cat allergen and histamine.\",\n",
            "    \"abstract\": \"Ten asymptomatic patients with normal pulmonary function were selected for a double-blind trial of immunotherapy in cat-induced asthma. Each patient had a positive prick test to cat pelt extract and also a positive bronchial challenge response to the same extract. Patients were randomly assigned to active treatment or placebo groups and received weekly or biweekly injections over a 3 to 4-month period. The 5 patients who received the active treatment received a cumulative dose of cat pelt extract that ranged from 16.4 to 44.8 mg of total solid containing 1.7 to 4.7 mg of cat allergen 1. Apparent systemic reactions were observed in 3 patients who received the placebo and 3 patients who received the active treatment. The 5 patients who received the active treatment showed a reduction in skin reactivity to cat pelt extract as well as a significant mean reduction in bronchial sensitivity to the same extract. The 5 patients who received the placebo showed no significant changes in skin reactivity or bronchial sensitivity to cat pelt extract. Bronchial response to histamine did not change significantly in either the active treatment of the placebo group.\"\n",
            "  },\n",
            "  {\n",
            "    \"is_clinical_trial\": false,\n",
            "    \"pubmed_id\": 27455824,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the data\n",
        "\n",
        "Let's get this data loaded and start looking at it.\n",
        "\n",
        "**Exercise:** Load the `asthma_dataset.json` into a variable called `documents` and check how many documents are in the dataset."
      ],
      "metadata": {
        "id": "tJZoj_MG9uKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "import json\n",
        "with open('asthma_dataset.json') as f:\n",
        "    documents = json.load(f)\n",
        "\n",
        "len(documents)"
      ],
      "metadata": {
        "id": "Mtvpy7ydkZld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae1c520-2f48-4a7d-a24a-e21932cd29ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1021"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see that there are 1021 documents.\n",
        "\n",
        "Let's take a look at the first couple of documents. The first document is a clinical trial and even mentions it in the title. The second article is about asthma but is about the cost of treatment. Could the word `trial` be enough to identify papers talking about clinical trials?"
      ],
      "metadata": {
        "id": "wjv_YnSxBsMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents[:2]"
      ],
      "metadata": {
        "id": "6vlqhig9BrcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80193d4-cfe9-49a2-b121-bb55be45f87f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'is_clinical_trial': True,\n",
              "  'pubmed_id': 346628,\n",
              "  'title': 'Immunotherapy in cat-induced asthma. Double-blind trial with evaluation of bronchial responses to cat allergen and histamine.',\n",
              "  'abstract': 'Ten asymptomatic patients with normal pulmonary function were selected for a double-blind trial of immunotherapy in cat-induced asthma. Each patient had a positive prick test to cat pelt extract and also a positive bronchial challenge response to the same extract. Patients were randomly assigned to active treatment or placebo groups and received weekly or biweekly injections over a 3 to 4-month period. The 5 patients who received the active treatment received a cumulative dose of cat pelt extract that ranged from 16.4 to 44.8 mg of total solid containing 1.7 to 4.7 mg of cat allergen 1. Apparent systemic reactions were observed in 3 patients who received the placebo and 3 patients who received the active treatment. The 5 patients who received the active treatment showed a reduction in skin reactivity to cat pelt extract as well as a significant mean reduction in bronchial sensitivity to the same extract. The 5 patients who received the placebo showed no significant changes in skin reactivity or bronchial sensitivity to cat pelt extract. Bronchial response to histamine did not change significantly in either the active treatment of the placebo group.'},\n",
              " {'is_clinical_trial': False,\n",
              "  'pubmed_id': 27455824,\n",
              "  'title': 'The Cost of Asthma Treatment in Phramongkutlao Hospital: Population-Based Study in Adults.',\n",
              "  'abstract': \"Asthma is a chronic respiratory disease that affects patients' quality of life and work performance. The cost of asthma treatment is a global economic burden. The costs include the direct medical costs and the indirect costs, such as the loss of productivity, which is difficult to quantify. Analyze the cost of asthma treatment in Thailand. Seventy-four asthmatic patients who had exacerbation were enrolled in the present study. Self-answer questionnaires were completed by the subjects including characteristics, socioeconomic factors, and level of asthma control by asthma control test (ACT) score. We evaluated the cost of asthma treatment calculated from direct medical, direct non-medical, and indirect medical costs. The average total cost per month was 2,752 Thai baht (US$ 86). The direct medical, direct non-medical, and indirect medical costs were 52.39%, 20.73%, and 26.88%, respectively. The direct medical costs accounted for quick-relief medications 11.91% and control medications 36.85% of the total medical cost. Loss of productivity, loss of work caused by asthma exacerbation, was the majority cost of non-medical costs. The average cost of treatment in uncontrolled was higher than partly controlled asthmatic patients but without significant difference. Healthcare payment system and age range affected the total costs of asthma treatment. The direct non-medical costs and indirect medical costs tend to play an important role of asthma treatment. The data suggested that cost savings could be achieved by improving asthma control.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's a good idea to dig around in the data to see if there are any oddities. Maybe some documents are missing titles or abstracts? Or could there be whole documents in there? It's always good to know these things.\n",
        "\n",
        "**Exercise:** Find out the minimum and maximum lengths of the `abstract` field across all the documents"
      ],
      "metadata": {
        "id": "phJTr7BBCPaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "import sys\n",
        "\n",
        "min_abstract_length = sys.maxsize\n",
        "max_abstract_length = -1\n",
        "for document in documents:\n",
        "  len_abstract = len(document['abstract'])\n",
        "  min_abstract_length = min(min_abstract_length, len_abstract)\n",
        "  max_abstract_length = max(max_abstract_length, len_abstract)\n",
        "\n",
        "print(\"minimum\", min_abstract_length)\n",
        "print(\"maximum\", max_abstract_length)"
      ],
      "metadata": {
        "id": "p_fJbPAjoYAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2193f6-eb4d-453a-d4c9-e7d45c81651b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum 161\n",
            "maximum 4140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see that the minimum length is 161 characters and maximum is 4140 characters. That's quite a spread. From a tweet up to a short essay.\n",
        "\n",
        "Now it's time to prepare the data for the classification task. Let's create two lists to separate the target labels (`is_clinical_trial`) from the text field that we'll use. The two lists are called `labels` and `texts`. We'll combine the `title` and `abstract` field like we did for the Reddit data in previous labs."
      ],
      "metadata": {
        "id": "ApxoZUl6owmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels, texts = [], []\n",
        "\n",
        "for doc in documents:\n",
        "  labels.append(doc['is_clinical_trial'])\n",
        "  texts.append(doc['title'] + '\\n' + doc['abstract'])"
      ],
      "metadata": {
        "id": "FYZ-XQq45Hdy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's check what the distribution of labels is:"
      ],
      "metadata": {
        "id": "JVgCXsGVEmxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(labels)\n"
      ],
      "metadata": {
        "id": "hoKl9A3u5anb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9154d352-c5c7-4f6c-c3f1-1efad7b9b70d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({True: 327, False: 694})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see that there are 327 True labels and 694 False labels."
      ],
      "metadata": {
        "id": "E4S4dXVqozsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the data into training, validation and testing datasets\n",
        "\n",
        "As discussed in the lecture, we need to split the dataset into parts to train and parts to evaluate. This is known as **cross-validation**. Let's split our dataset of 1021 `labels` and `texts` into training, validation and test splits.\n",
        "\n",
        "**Exercise:** Use scikit-learn's [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to split the dataset into three parts using a 60%/20%/20% split for training, validation and testing respectively. You'll need to call [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) twice. First to split the `labels` and `texts` into 80%/20% to get the train+val and the test set. Then call it again on the train+val with a 75%/25% split. You'll want to use the `test_size` parameter and use `random_state=42` to get the same results as everyone else.\n",
        "\n",
        "The six outputs should be called `texts_train`, `labels_train`, `texts_val`, `labels_val`, `texts_test` and `labels_test`."
      ],
      "metadata": {
        "id": "pTcbSuqq-Ifk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "texts_training, texts_test, labels_training, labels_test = train_test_split(texts, labels, train_size=0.8, test_size=0.2, random_state=42)\n",
        "# print(len(texts_training), len(texts_test), len(labels_training), len(labels_test))\n",
        "\n",
        "texts_train, texts_val, labels_train, labels_val = train_test_split(texts_training, labels_training, train_size=0.75, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "SgwBYpyY5d4R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the size of the different parts after the split."
      ],
      "metadata": {
        "id": "aBVWmnHTHMvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(texts_train)=}\\t{len(labels_train)=}\")\n",
        "print(f\"{len(texts_val)=}\\t{len(labels_val)=}\")\n",
        "print(f\"{len(texts_test)=}\\t{len(labels_test)=}\")"
      ],
      "metadata": {
        "id": "qfzmep9hFURl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d934e9a-3ea7-479f-8dc0-4a2c3a3c3b3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(texts_train)=612\tlen(labels_train)=612\n",
            "len(texts_val)=204\tlen(labels_val)=204\n",
            "len(texts_test)=205\tlen(labels_test)=205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see that the dataset has been split into parts with sizes 612, 204 and 205. And that the corresponding `texts_*` and `labels_*` parts are the same sizes.\n",
        "\n",
        "And let's check if we got the desired 60%/20%/20% split."
      ],
      "metadata": {
        "id": "iDOP3za-HWK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(texts_train) + len(texts_val) + len(texts_test)\n",
        "len(texts_train)/total, len(texts_val)/total, len(texts_test)/total"
      ],
      "metadata": {
        "id": "cBJn1MRj5ltO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ca3976-cbcd-409e-c823-99721e653778"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5994123408423114, 0.19980411361410383, 0.2007835455435847)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yep, that's probably as close as we could get to 60%/20%/20% when splitting up 1021 documents."
      ],
      "metadata": {
        "id": "y1OTco3fHmfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why training, validation and testing?\n",
        "\n",
        "As mentioned in the lectures, we want part of the data to build a classifier and part to evaluate with. So why not just training and test? Using a validation set allows us to try a lot more experiments to test out different approaches without the worry that we're overfitting on the test set.\n",
        "\n",
        "Good practice is to avoid touching the test set until your final set of experiments. We'll forget about the test data until the end of the lab and use the training and validation splits for now."
      ],
      "metadata": {
        "id": "xTzGM_W8-Npg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build your own classifier\n",
        "\n",
        "Earlier, we noticed that the word \"trial\" appeared in the first document talking about clinical trials. Maybe the existence of the word \"trial\" would be enough to identify clinical trials?\n",
        "\n",
        "**Exercise:** Iterate over the validation set `texts_val` and check if the string \"trial\" appears in each text. Save the prediction (which should be `True` or `False`) to a list called `labels_predicted`. You do not need to do any parsing. You can use the string [count](https://www.w3schools.com/python/ref_string_count.asp) method."
      ],
      "metadata": {
        "id": "BDOKzmlN-e-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "labels_predicted = [ \"trial\" in text.lower() for text in texts_val]"
      ],
      "metadata": {
        "id": "j3MFjti7-hc0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check how many predictions of each label we have using a `Counter`:"
      ],
      "metadata": {
        "id": "ZsgYanW7I2OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(labels_predicted)"
      ],
      "metadata": {
        "id": "hk7hfs73IQjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eecf5997-ac8d-4fd5-cd4d-c70af09d4725"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({False: 176, True: 28})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should have 176 False predictions and 28 True Predictions (totalling 204 for the size of the validation set).\n",
        "\n",
        "**Congratulations!** You have written a machine learning classifier. It may be a simple rule-based approach but sometimes simple is all you need. This type of classifier is known as a [decision stump](https://en.wikipedia.org/wiki/Decision_stump) where a single decision is used to classify the data.\n",
        "\n",
        "But is it any good?"
      ],
      "metadata": {
        "id": "-7749fmsI5R2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate your own classifier\n",
        "\n",
        "Now let's compare our predictions `labels_predicted` against the actual labels `labels_val`. We'll need the four numbers that make up a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) for a binary classification problem:\n",
        "\n",
        "- True positive count: Where the actual label is True and predicted label is True\n",
        "- False positive count: Where the actual label is False and predicted label is True\n",
        "- False negative count: Where the actual label is True and predicted label is False\n",
        "- True negative count: Where the actual label is False and predicted label is False\n",
        "\n",
        "**Exercise:** Calculate the counts of true positives, false positives, false negatives and true negatives when comparing `labels_predicted` and `labels_val`.\n",
        "\n",
        "*Tip:* Python's [zip function](https://docs.python.org/3.3/library/functions.html#zip) is useful for this."
      ],
      "metadata": {
        "id": "ufZOZTLl--A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "labels_diff = zip(labels_predicted, labels_val)\n",
        "tp, fp, fn, tn = 0, 0, 0, 0\n",
        "for data in labels_diff:\n",
        "  truth = data[1]\n",
        "  predicted = data[0]\n",
        "\n",
        "  if truth==predicted :\n",
        "    if truth == True:\n",
        "      tp+=1\n",
        "    else:\n",
        "      tn+=1\n",
        "  else:\n",
        "    if predicted == True:\n",
        "      fp+=1\n",
        "    else:\n",
        "      fn+=1\n",
        "\n",
        "print(\"tp\", tp)\n",
        "print(\"fp\", fp)\n",
        "print(\"fn\", fn)\n",
        "print(\"tn\", tn)"
      ],
      "metadata": {
        "id": "gRlfA_0i_HNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aff44cf-27bb-4cd5-f3eb-0bae5ce7dfd1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tp 20\n",
            "fp 8\n",
            "fn 52\n",
            "tn 124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should get 20 true positives, 8 false positives, 52 false negatives and 124 true negatives. So it does identify quite a few documents correctly as describing clinical trials but misses many more.\n",
        "\n",
        "The raw counts of a confusion matrix can be a little challenging to comprehend. It gets harder if you want to compare multiple classifier results. Let's turn the counts into some of the standard metrics we will use:\n",
        "\n",
        "- $ accuracy = \\frac{TP+TN}{TP+FP+FN+TN} $\n",
        "\n",
        "- $ precision = \\frac{TP}{TP+FP} $\n",
        "\n",
        "- $ recall = \\frac{TP}{TP+FN} $\n",
        "\n",
        "- $ F_1 = 2\\frac{precision \\times recall}{precision + recall} $\n",
        "\n",
        "**Exercise:** Calculate the $accuracy$, $precision$, $recall$ and $F_1 score$ with the confusion matrix counts to 3 decimal places.\n",
        "\n",
        "*Tip:* You can output a number nicely using [f-strings](https://docs.python.org/3/tutorial/inputoutput.html#formatted-string-literals). To output the variable `x` to 5 decimal places, you could use `print(f\"{x:.5f}\")`"
      ],
      "metadata": {
        "id": "zAhWrVk6__f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
        "precision = (tp)/(tp+fp)\n",
        "recall = (tp)/(tp+fn)\n",
        "f1 = 2*((precision*recall)/(precision+recall))\n",
        "\n",
        "print(f\"accuracy {accuracy:.3f}\")\n",
        "print(f\"precision {precision:.3f}\")\n",
        "print(f\"recall {recall:.3f}\")\n",
        "print(f\"f1 {f1:.3f}\")"
      ],
      "metadata": {
        "id": "AUy8X85L_qe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b39a3ea-bef7-443b-a99d-1b1e908864f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.706\n",
            "precision 0.714\n",
            "recall 0.278\n",
            "f1 0.400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should get accuracy=0.706, precision=0.714, recall=0.278 and f1=0.400. The precision is on the higher end as it doesn't predict too many false positives, but the recall is low as there are many false negatives.\n",
        "\n",
        "*Bonus tip:* practically you only want to give a few decimal places when reporting results. It can look odd to give 10 decimal places, and it can make the numbers more challenging to read. The numbers at the 5th and 6th decimal place are likely not very important. Three decimal places are often sufficient.\n",
        "\n",
        "Scikit-learn offers some useful functions to calculate the confusion matrix counts as well as the different evaluation metrics directly.\n",
        "\n",
        "**Exercise:** Use scikit-learn's [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function to calculate the true positive, false positive, false negative and true negative counts of the actual labels `labels_val` and the predicted labels `labels_predicted` from above. The counts should be the same as you calculated earlier"
      ],
      "metadata": {
        "id": "z7abv4NLAJun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "from sklearn.metrics import confusion_matrix\n",
        "result = confusion_matrix(labels_val, labels_predicted)\n",
        "result"
      ],
      "metadata": {
        "id": "QUCizu9r-7-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca848500-c291-43ed-a64c-99ec215e8b14"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[124,   8],\n",
              "       [ 52,  20]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's get the evaluation metrics with scikit-learn.\n",
        "\n",
        "**Exercise:** Use [scikit-learn metrics functions](https://scikit-learn.org/stable/modules/model_evaluation.html) to calculate the accuracy, precision, recall and f1 scores of our earlier predictions `labels_predicted` against the actual labels `labels_val`."
      ],
      "metadata": {
        "id": "twlqyslDrLxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "from sklearn import metrics\n",
        "accuracy = metrics.accuracy_score(labels_val, labels_predicted)\n",
        "precision = metrics.precision_score(labels_val, labels_predicted)\n",
        "recall = metrics.recall_score(labels_val, labels_predicted)\n",
        "f1 =  metrics.f1_score(labels_val, labels_predicted)\n",
        "\n",
        "print(f\"accuracy {accuracy:.3f}\")\n",
        "print(f\"precision {precision:.3f}\")\n",
        "print(f\"recall {recall:.3f}\")\n",
        "print(f\"f1 {f1:.3f}\")"
      ],
      "metadata": {
        "id": "BsSmX2zvBQep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a41dfcb-3d8a-4a04-9033-b2c3d7ae529e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.706\n",
            "precision 0.714\n",
            "recall 0.278\n",
            "f1 0.400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may want to make a figure from the confusion matrix. Scikit-learn offers a function [ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html) that displays the confusion matrix."
      ],
      "metadata": {
        "id": "7x6EIrvBsstG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(labels_val, labels_predicted)\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['not clinical trial','clinical trial']).plot()"
      ],
      "metadata": {
        "id": "KgqSjvHCok8F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "558291df-875c-4892-f52c-2bbd8d5547db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x79edff4035e0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be nice to have a bit more control over the plotting. Here's some code using a plotting library called [seaborn](https://seaborn.pydata.org/) that outputs a labeled confusion matrix. It allows you to use a custom colour palette including [ColorBrewer](https://colorbrewer2.org/) which is commonly used for making nice plots. Here we use the `Reds` palette, but there are [many more](https://seaborn.pydata.org/tutorial/color_palettes.html). Some are recommended for colour-blind audiences or for printing."
      ],
      "metadata": {
        "id": "XeI-KTXkolFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "\n",
        "def plotConfusionMatrix(labels_val, labels_predicted):\n",
        "  cm = confusion_matrix(labels_val, labels_predicted)\n",
        "  colour_map = sn.color_palette(\"Reds\", as_cmap=True)\n",
        "  labels = ['not clinical trial', 'clinical trial']\n",
        "  plot = sn.heatmap(cm,\n",
        "                    annot=True, # Put the numbers in\n",
        "                    annot_kws={\"size\": 16}, # Make the numbers bigger\n",
        "                    fmt='g', # Stop scientific notation\n",
        "                    cmap = colour_map, # Choose the colour palette\n",
        "                    cbar = False, # Don't include the colour bar\n",
        "                    xticklabels=labels, # Put in the X and Y labels\n",
        "                    yticklabels=labels)\n",
        "  plot.set(xlabel='Predicted', ylabel='Actual')\n",
        "  return plot\n",
        "\n",
        "plotConfusionMatrix(labels_val, labels_predicted)"
      ],
      "metadata": {
        "id": "ZeolcJivAebZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "f6090c68-971e-4ef4-cadb-9c35761085eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Predicted', ylabel='Actual'>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Extra tip:* Scikit-learn also has a nice function [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) which is useful for multi-class classification problems. It's not as useful for binary problems."
      ],
      "metadata": {
        "id": "4w3XDPEgzY4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a dummy classifier\n",
        "\n",
        "We got an accuracy of 0.706. Is that good? Well, it depends on the class balance, which in this dataset is the balance of positive and negative labels.\n",
        "\n",
        "At the beginning, we calculated the label counts for the whole dataset and know that the negatives are in the majority. What if the classifier always predicted False?\n",
        "\n",
        "**Exercise:** Make another classifier (not using scikit-learn) that always predicts False for every sample in the validation set. Store the result to `labels_predicted` again."
      ],
      "metadata": {
        "id": "58GqEha6m_vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "labels_predicted = [False for i in range(len(texts_val))]"
      ],
      "metadata": {
        "id": "Qjf020LfnEb6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** Calculate the accuracy of these new predictions using scikit-learn. *Tip:* copy your scikit-learn code from above"
      ],
      "metadata": {
        "id": "xcZ3fBFTu5SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "accuracy = metrics.accuracy_score(labels_val, labels_predicted)\n",
        "print(f\"accuracy {accuracy:.3f}\")\n"
      ],
      "metadata": {
        "id": "_fODkxN2pXrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e06a9d0-f5a9-4738-cc4c-575fe625a401"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Huh, the accuracy of always predicting False is 0.647. So 0.704 is better, but not by that much.\n",
        "\n",
        "Where does the 0.647 come from?\n",
        "\n",
        "**Exercise:** Calculate the percentage of False labels in `labels_val`. You could use a [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) again or you can use [sum](https://docs.python.org/3/library/functions.html#sum) to add up lists of boolean values."
      ],
      "metadata": {
        "id": "fdtuLc8DvD_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "labels_counter = Counter(labels_val)\n",
        "false_percentage = labels_counter[False]/(labels_counter[False]+labels_counter[True])\n",
        "false_percentage"
      ],
      "metadata": {
        "id": "mTfKK01hs87q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94aadc9-fe67-45d8-eb10-7cc6191c9273"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6470588235294118"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy score matches the majority class percentage. So, for really extreme class imbalances (like 1% positive labels), guessing the most frequent class will get you a very high accuracy score - which is not helpful. That's why we need to use other metrics like precision, recall and F1.\n",
        "\n",
        "*Extra tip:* Scikit-learn offers a [dummy classifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) that can use basic strategies like guessing the most frequent class. This can provide a baseline to compare other scores against.\n",
        "\n",
        "**Exercise:** Now calculate the precision, recall and F1 scores of these new predictions `labels_predicted` against the actual labels `labels_val` using scikit-learn functions. *Tip:* Copy your code again from above."
      ],
      "metadata": {
        "id": "-8t9TCGkvs2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "accuracy = metrics.accuracy_score(labels_val, labels_predicted)\n",
        "precision = metrics.precision_score(labels_val, labels_predicted)\n",
        "recall = metrics.recall_score(labels_val, labels_predicted)\n",
        "f1 =  metrics.f1_score(labels_val, labels_predicted)\n",
        "\n",
        "print(f\"accuracy {accuracy:.3f}\")\n",
        "print(f\"precision {precision:.3f}\")\n",
        "print(f\"recall {recall:.3f}\")\n",
        "print(f\"f1 {f1:.3f}\")"
      ],
      "metadata": {
        "id": "eskVuZhYnotT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4705c6-ce26-4cf3-9c8e-d8b172183fd6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.647\n",
            "precision 0.000\n",
            "recall 0.000\n",
            "f1 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow, zeros for precision, recall and F1. This is not a good classifier even though the accuracy looked okay.\n",
        "\n",
        "Notice the warning about precision being ill-defined. If the denominators in the equations for precision, recall or F1 are zero, you have a divide by zero and the metric is not defined. Scikit-learn will still return a zero, but you may get a warning."
      ],
      "metadata": {
        "id": "krWnU7X2v9Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a scikit-learn classifier\n",
        "\n",
        "Now, we've created our own classifier that looked for the word `trial` and a dummy classifier that always predicted the most frequent class. Let's create an actual classifier based on the word frequencies in the documents.\n",
        "\n",
        "First, we want to vectorize the documents and turn each one into a TF-IDF vector. This will give us feature matrices that we can use for our classifiers.\n",
        "\n",
        "**Exercise:** Fit a [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to the training text (`texts_train`), transform the training text and the validation text. Use the default parameters for TfidfVectorizer. You may want to check previous labs for using TfidfVectorizer. Output the matrix dimensions (`.shape`) of the vectorized training and validation texts."
      ],
      "metadata": {
        "id": "mEWu-jfZ-Ty9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_train_text = vectorizer.fit_transform(texts_train)\n",
        "print(vectorized_train_text.shape)\n",
        "\n",
        "vectorized_val_text = vectorizer.transform(texts_val)\n",
        "print(vectorized_val_text.shape)\n",
        "\n",
        "# vectorized_test_text = vectorizer.transform(texts_test)\n",
        "# print(vectorized_test_text.shape)"
      ],
      "metadata": {
        "id": "O44MyLCy6smw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9392c80c-b2bd-4fb4-d50b-d7f65419bcf3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(612, 9321)\n",
            "(204, 9321)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should have a training dataset with dimensions (612,9321) and a validation feature matrix with dimensions (204, 9321).\n",
        "\n",
        "We've got the feature matrices that we need to train a scikit-learn classifier. We'll look at one of the standard ones: Logistic Regression.\n",
        "\n",
        "**Exercise:** Fit a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier to the training feature matrix (that you got from the TfidfVectorizer) and the training labels (`labels_train`). Then make predictions on the validation data (using its feature matrix). Save the predictions to the `labels_predicted` variable and check its length. Use the defaults with a `random_state=42`."
      ],
      "metadata": {
        "id": "6IGvOVFKycK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression(random_state=42)\n",
        "lr_model.fit(vectorized_train_text, labels_train)\n",
        "\n",
        "labels_predicted = lr_model.predict(vectorized_val_text)"
      ],
      "metadata": {
        "id": "IU7VVbWK7EuC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should have 204 predictions that matches the size of the validation set.\n",
        "\n",
        "Let's see what the confusion matrix of our new predictions `labels_predicted` with Logistic Regression looks like:"
      ],
      "metadata": {
        "id": "o9oq7KCE0Xl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotConfusionMatrix(labels_val, labels_predicted)"
      ],
      "metadata": {
        "id": "sfxP16o-7WNg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "9148608e-2560-4453-8543-f273786f534f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Predicted', ylabel='Actual'>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see 132 true negatives, 0 false positives, 41 false negatives and 31 true positives.\n",
        "\n",
        "**Exercise:** Now we know that accuracy isn't good for this dataset, calculate the precision, recall and F1 scores to three decimal places."
      ],
      "metadata": {
        "id": "dgdRpj1A03FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "accuracy = metrics.accuracy_score(labels_val, labels_predicted)\n",
        "precision = metrics.precision_score(labels_val, labels_predicted)\n",
        "recall = metrics.recall_score(labels_val, labels_predicted)\n",
        "f1 =  metrics.f1_score(labels_val, labels_predicted)\n",
        "\n",
        "print(f\"accuracy {accuracy:.3f}\")\n",
        "print(f\"precision {precision:.3f}\")\n",
        "print(f\"recall {recall:.3f}\")\n",
        "print(f\"f1 {f1:.3f}\")"
      ],
      "metadata": {
        "id": "XLr9g_Is3phZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41af2f58-d945-4934-8644-857a74227329"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.799\n",
            "precision 1.000\n",
            "recall 0.431\n",
            "f1 0.602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's great precision! All of the documents it predicts to be clinical trial reports are. The recall is on the lower end though."
      ],
      "metadata": {
        "id": "Y7ave66nUZsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating on the training set\n",
        "\n",
        "The most useful evaluation metrics is on a **held-out** dataset - one which was not used for training the classifier. However, it is sometimes useful to see how the classifier performs on the training set. If it performs very very well on the training set, and much worse on the validation set, it is likely that the classifier has [overfit](https://en.wikipedia.org/wiki/Overfitting) the training set. This can depend on the specific algorithm of the classifier\n",
        "\n",
        "Let's check out the performance metrics on the training set.\n",
        "\n",
        "**Exercise:** Use the existing classifier to make predictions on the training vectors and calculate the precision, recall and F1 scores against the training labels `labels_train`."
      ],
      "metadata": {
        "id": "1FOtIce5B3D9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "labels_predicted = lr_model.predict(vectorized_train_text)\n",
        "\n",
        "accuracy = metrics.accuracy_score(labels_train, labels_predicted)\n",
        "precision = metrics.precision_score(labels_train, labels_predicted)\n",
        "recall = metrics.recall_score(labels_train, labels_predicted)\n",
        "f1 =  metrics.f1_score(labels_train, labels_predicted)\n",
        "\n",
        "print(f\"accuracy {accuracy:.3f}\")\n",
        "print(f\"precision {precision:.3f}\")\n",
        "print(f\"recall {recall:.3f}\")\n",
        "print(f\"f1 {f1:.3f}\")"
      ],
      "metadata": {
        "id": "u_mOm6SCClp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432b7ffe-94b5-47a8-b804-145c3e7ce349"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.887\n",
            "precision 0.984\n",
            "recall 0.651\n",
            "f1 0.784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see training precision=0.984, training recall=0.651 and training f1=0.784. The F1 score is higher on the training set than the validation set so some amount of overfitting is likely happening. Note that the classifier performance will almost always be better on the training set than the validation set."
      ],
      "metadata": {
        "id": "fFwe4ijLDEOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying out different pipelines\n",
        "\n",
        "We've got one machine learning pipeline (from text data, to vectorized data, to a classifier and to predictions). We now want to try out some other pipelines and see if we can make any improvements."
      ],
      "metadata": {
        "id": "mzQYOn0z1Ovf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Spacy for tokenization\n",
        "\n",
        "We used the defaults for the TfidfVectorizer before. One of those defaults is how to do the tokenization. The TfidfVectorizer uses a fairly basic technique to split up text into tokens. Let's see if using Spacy improves anything.\n",
        "\n",
        "Below is code from a previous lab to tokenize text using Spacy."
      ],
      "metadata": {
        "id": "4uI37J5omb0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def text_pipeline_spacy(text):\n",
        "    tokens = []\n",
        "    doc = nlp(text)\n",
        "    for t in doc:\n",
        "        if not t.is_stop and not t.is_punct and not t.is_space:\n",
        "            tokens.append(t.lemma_.lower())\n",
        "    return tokens\n",
        "\n",
        "# Example usage:\n",
        "text_pipeline_spacy(\"Of all the things I miss, I miss my mind the most.\")"
      ],
      "metadata": {
        "id": "oaugEKBK8SoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a9a174-9c66-4fe6-aeb1-b1f33a831438"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thing', 'miss', 'miss', 'mind']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** Run the machine learning pipeline again using this new tokenization - essentially copy the various steps of scikit-learn from above and change the TfidfVectorizer. Specifically: vectorize the training and validation data with a [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) that uses the `text_pipeline_spacy` function as its tokenizer. Train a new LogisticRegression classifier on the training labels and new training feature matrix. Make predictions on the validation set and calculate the F1-score. As before, use `random_state=42` and no other parameters for LogisticRegression\n",
        "\n",
        "This may take a minute to run."
      ],
      "metadata": {
        "id": "3XYeGPnP2QmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "vectorizer = TfidfVectorizer(tokenizer=text_pipeline_spacy)\n",
        "vectorized_train_text = vectorizer.fit_transform(texts_train)\n",
        "print(vectorized_train_text.shape)\n",
        "\n",
        "vectorized_val_text = vectorizer.transform(texts_val)\n",
        "print(vectorized_val_text.shape)\n",
        "\n",
        "lr_model = LogisticRegression(random_state=42)\n",
        "lr_model.fit(vectorized_train_text, labels_train)\n",
        "\n",
        "labels_predicted = lr_model.predict(vectorized_val_text)\n",
        "\n",
        "accuracy = metrics.accuracy_score(labels_val, labels_predicted)\n",
        "precision = metrics.precision_score(labels_val, labels_predicted)\n",
        "recall = metrics.recall_score(labels_val, labels_predicted)\n",
        "f1 =  metrics.f1_score(labels_val, labels_predicted)\n",
        "\n",
        "print(f\"accuracy {accuracy:.3f}\")\n",
        "print(f\"precision {precision:.3f}\")\n",
        "print(f\"recall {recall:.3f}\")\n",
        "print(f\"f1 {f1:.3f}\")\n"
      ],
      "metadata": {
        "id": "nZRsz7DA7c5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13499013-95e6-4740-c02a-99a9540a4f30"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(612, 9297)\n",
            "(204, 9297)\n",
            "accuracy 0.809\n",
            "precision 1.000\n",
            "recall 0.458\n",
            "f1 0.629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should get an F1 score of 0.629 so slightly better with this tokenization strategy."
      ],
      "metadata": {
        "id": "Zsoalmjk4FHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing the hyperparameters\n",
        "\n",
        "Looking at the scikit-learn pages for the [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), there are a lot of options you can tweak that will affect how the classifier behaves. These are known as hyperparameters. Let's try out a different setting. The `C` hyperparameter of a Logistic Regression classifier controls a feature known as [regularization](https://en.wikipedia.org/wiki/Regularization_(mathematics)). This can stop a classifier from overfitting by limiting the weights that the classifier puts on different individual features. A higher `C` lowers the amount of regularization.\n",
        "\n",
        "**Exercise:** Run the machine learning pipeline (vectorizing, building classifier and making predictions) with a TfidfVectorizer using its default tokenization (no Spacy) and the LogisticRegression with parameter `C=5` and `random_state=42`. Calculate the F1-score of the predictions on the validation dataset."
      ],
      "metadata": {
        "id": "PE4mi08DmhP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_train_text = vectorizer.fit_transform(texts_train)\n",
        "print(vectorized_train_text.shape)\n",
        "\n",
        "vectorized_val_text = vectorizer.transform(texts_val)\n",
        "print(vectorized_val_text.shape)\n",
        "\n",
        "lr_model = LogisticRegression(C=5, random_state=42)\n",
        "lr_model.fit(vectorized_train_text, labels_train)\n",
        "\n",
        "labels_predicted = lr_model.predict(vectorized_val_text)\n",
        "\n",
        "accuracy = metrics.accuracy_score(labels_val, labels_predicted)\n",
        "precision = metrics.precision_score(labels_val, labels_predicted)\n",
        "recall = metrics.recall_score(labels_val, labels_predicted)\n",
        "f1 =  metrics.f1_score(labels_val, labels_predicted)\n",
        "\n",
        "print(f\"accuracy {accuracy:.3f}\")\n",
        "print(f\"precision {precision:.3f}\")\n",
        "print(f\"recall {recall:.3f}\")\n",
        "print(f\"f1 {f1:.3f}\")"
      ],
      "metadata": {
        "id": "yxHFRHwSmjP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a89c84-8af3-491b-b85f-09d0fde0e895"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(612, 9321)\n",
            "(204, 9321)\n",
            "accuracy 0.858\n",
            "precision 0.978\n",
            "recall 0.611\n",
            "f1 0.752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should get an F1 score of 0.752. Even better!"
      ],
      "metadata": {
        "id": "k1FAfOw4FWUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuning the hyperparameters\n",
        "\n",
        "There are a lot of hyperparameters that can be tweaked. It is standard practice to try out a bunch of hyperparameter settings with training on the training set and evaluating on the validation set.\n",
        "\n",
        "Searching across all possible settings (given lists of each possible desired setting for each hyperparameter) is known as [grid search](https://en.wikipedia.org/wiki/Hyperparameter_optimization).\n",
        "\n",
        "Scikit-learn provides a nice feature known as [ParameterGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html) that allows you to list the possible settings for each hyperparameter and to then iterate over the different settings. The code below illustrates it for two imagined hyperparameters `a` and `b`."
      ],
      "metadata": {
        "id": "jR9WfyHTmfQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "param_grid = {'a': [1, 2], 'b': [True, False]}\n",
        "\n",
        "for params in ParameterGrid(param_grid):\n",
        "    print(params)"
      ],
      "metadata": {
        "id": "eqwZbudqmymO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c70926-a4e0-4ab1-b3bd-8bef9b6e583c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 1, 'b': True}\n",
            "{'a': 1, 'b': False}\n",
            "{'a': 2, 'b': True}\n",
            "{'a': 2, 'b': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practically the number of possible settings may be so vast that the computational cost of trying them all using grid search is infeasible. You would likely pick a small number of hyperparameters that are known to have a big effect and also choose a limited set of possible values for them.\n",
        "\n",
        "You may also try a strategy other than grid search, such as optimising one hyperparameter at a time before moving onto the next or some form of random search. There are many strategies for this problem known as [hyperparameter optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization). But for now, we'll stick with grid search.\n",
        "\n",
        "**Exercise:** Using a [ParameterGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html), try out different settings for the `C` for Logistic Regression (try 1 or 10) and `max_df` for TfidfVectorizer (try 0.7 or 1.0). Again, don't use Spacy for tokenization (for speed) and use `random_state=42` for the Logistic Regression classifier. Save the hyperparameter settings that give the highest F1 score on the validation set."
      ],
      "metadata": {
        "id": "W3c78c-36Jt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "best_f1_score = -1\n",
        "best_params = None\n",
        "param_grid = {'C': list(range(1,11)), 'max_df': [0.7, 1.0]}\n",
        "for params in ParameterGrid(param_grid):\n",
        "  vectorizer = TfidfVectorizer(max_df=params['max_df'])\n",
        "  vectorized_train_text = vectorizer.fit_transform(texts_train)\n",
        "  # print(vectorized_train_text.shape)\n",
        "\n",
        "  vectorized_val_text = vectorizer.transform(texts_val)\n",
        "  # print(vectorized_val_text.shape)\n",
        "\n",
        "  lr_model = LogisticRegression(C=params['C'], random_state=42)\n",
        "  lr_model.fit(vectorized_train_text, labels_train)\n",
        "\n",
        "  labels_predicted = lr_model.predict(vectorized_val_text)\n",
        "  f1 =  metrics.f1_score(labels_val, labels_predicted)\n",
        "  if best_f1_score < f1:\n",
        "    best_f1_score = f1\n",
        "    best_params = params\n",
        "\n",
        "print(f\"Best f1 {best_f1_score:.3f} with {best_params}\")"
      ],
      "metadata": {
        "id": "pxbDANKEl_-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "461a2dd9-2df2-497c-8e91-4271fadf97c5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best f1 0.793 with {'C': 10, 'max_df': 0.7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should find that the settings (`C=10` and `max_df=0.7`) gives the best validation F1 score of 0.793.\n",
        "\n",
        "We've only tested out a LogisticRegression classifier. It's a good idea to try out a few other classifiers. Scikit-learn offers a large selection of classifier algorithms.\n",
        "\n",
        "**Exercise:** Pick another classifier from scikit-learn such as a K Nearest Neighbors Classifier, a Linear Support Vector classifier, a Random Forest classifier. Rerun the machine learning classifier with it and see how it performs on the validation set by calculating the F1 score."
      ],
      "metadata": {
        "id": "vbyFNc4W8bz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "best_f1_score = -1\n",
        "best_params = None\n",
        "param_grid = {'C': list(range(1,11)), 'max_df': [0.7, 1.0], 'kernel': ['linear', 'poly', 'rbf']}\n",
        "for params in ParameterGrid(param_grid):\n",
        "  vectorizer = TfidfVectorizer(max_df=params['max_df'])\n",
        "  vectorized_train_text = vectorizer.fit_transform(texts_train)\n",
        "  # print(vectorized_train_text.shape)\n",
        "\n",
        "  vectorized_val_text = vectorizer.transform(texts_val)\n",
        "  # print(vectorized_val_text.shape)\n",
        "\n",
        "  lr_model = SVC(C=params['C'], kernel=params['kernel'], random_state=42)\n",
        "  lr_model.fit(vectorized_train_text, labels_train)\n",
        "\n",
        "  labels_predicted = lr_model.predict(vectorized_val_text)\n",
        "  f1 =  metrics.f1_score(labels_val, labels_predicted)\n",
        "  if best_f1_score < f1:\n",
        "    best_f1_score = f1\n",
        "    best_params = params\n",
        "\n",
        "print(f\"Best f1 {best_f1_score:.3f} with {best_params}\")"
      ],
      "metadata": {
        "id": "rUxqOtSc8o5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0036fd7b-6650-470f-90ba-d95447413665"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best f1 0.841 with {'C': 2, 'kernel': 'linear', 'max_df': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error analysis\n",
        "\n",
        "As we're trying to squeeze more performance out of our machine learning pipeline, this is also a good time to understand what errors are happening. Essentially, what is our best classifier good at, and what is it not good at? This can lead us to create new custom features, annotate more specific data or other strategies to solve problems.\n",
        "\n",
        "A good practice is to randomly select some false positives and false negatives (the mistakes) from the validation set and to manually check why they are mistakes. This may require expert knowledge of the text (as in the case of clinical trial reports). Some common outcomes of this analysis:\n",
        "- The useful features that you can see when you look at the text are not being captured by the features (maybe trigrams are essential)\n",
        "- The class is so rare that the classifier is having a hard time distinguishing it from the majority class.\n",
        "  - More data may be required - or other tricks to deal with class imbalance.\n",
        "- They are not mistakes and the labels are wrong\n",
        "- The classifier has a problem with certain types of data\n",
        "  - For the clinical trial reports, there could a type of trial that is described completely differently from others\n",
        "\n",
        "For multiclass problems, the confusion matrix can also tell you what classes are being confused with others.\n",
        "\n",
        "We won't dive into the data to do error analysis in this lab.\n"
      ],
      "metadata": {
        "id": "m3WQR_Gf-UfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating on the test set\n",
        "\n",
        "At the end of a machine learning project, when you have done all your experiments on the training & validation sets, it is finally time to turn to the **test set**. You shouldn't use it in training and tuning your model. It should only be used for evaluation and the less you use it the better.\n",
        "\n",
        "For this lab, don't worry about rerunning things on the test set.\n",
        "\n",
        "**Exercise:** Take your best pipeline (vectorizer & classifier) approach from above. Train it on the training data and evaluate it on the test data (`texts_test` and `labels_test`). Calculate the Precision, Recall, and F1 score on the test set."
      ],
      "metadata": {
        "id": "h_mN8ZvWnOaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "vectorizer = TfidfVectorizer(max_df=1.0)\n",
        "vectorized_train_text = vectorizer.fit_transform(texts_train)\n",
        "vectorized_val_text = vectorizer.transform(texts_val)\n",
        "vectorized_test_text = vectorizer.transform(texts_test)\n",
        "\n",
        "lr_model = SVC(C=2, kernel='linear', random_state=42)\n",
        "lr_model.fit(vectorized_train_text, labels_train)\n",
        "\n",
        "## Validation\n",
        "labels_predicted = lr_model.predict(vectorized_val_text)\n",
        "\n",
        "accuracy = metrics.accuracy_score(labels_val, labels_predicted)\n",
        "precision = metrics.precision_score(labels_val, labels_predicted)\n",
        "recall = metrics.recall_score(labels_val, labels_predicted)\n",
        "f1 =  metrics.f1_score(labels_val, labels_predicted)\n",
        "\n",
        "print(\"Validation scores\")\n",
        "print(f\"accuracy {accuracy:.3f}\")\n",
        "print(f\"precision {precision:.3f}\")\n",
        "print(f\"recall {recall:.3f}\")\n",
        "print(f\"f1 {f1:.3f}\")\n",
        "print()\n",
        "# print(vectorized_test_text.shape)\n",
        "\n",
        "## Testing\n",
        "labels_predicted = lr_model.predict(vectorized_test_text)\n",
        "\n",
        "accuracy = metrics.accuracy_score(labels_test, labels_predicted)\n",
        "precision = metrics.precision_score(labels_test, labels_predicted)\n",
        "recall = metrics.recall_score(labels_test, labels_predicted)\n",
        "f1 =  metrics.f1_score(labels_test, labels_predicted)\n",
        "\n",
        "print(\"Testing scores\")\n",
        "print(f\"accuracy {accuracy:.3f}\")\n",
        "print(f\"precision {precision:.3f}\")\n",
        "print(f\"recall {recall:.3f}\")\n",
        "print(f\"f1 {f1:.3f}\")"
      ],
      "metadata": {
        "id": "KxRMeUMxnQ9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad6a717-9bcb-4c92-b8fe-dad098103baf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation scores\n",
            "accuracy 0.902\n",
            "precision 0.981\n",
            "recall 0.736\n",
            "f1 0.841\n",
            "\n",
            "Testing scores\n",
            "accuracy 0.878\n",
            "precision 0.896\n",
            "recall 0.683\n",
            "f1 0.775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may have found a higher performing classifier so your result may differ. If you used a LogisticRegression classifier with the best parameters from earlier (`C=10` and `max_df=0.7`), you should see an F1 score of 0.771.\n",
        "\n",
        "You can use the `plotConfusionMatrix` function again to plot your test results (if your predictions are again stored in `labels_predicted`)."
      ],
      "metadata": {
        "id": "Z7x5GJbzBER7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotConfusionMatrix(labels_test, labels_predicted)"
      ],
      "metadata": {
        "id": "KqHrD3egsqlu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "92072d9e-f549-4f2c-9308-cf3660ea4fc0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Predicted', ylabel='Actual'>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deployment?"
      ],
      "metadata": {
        "id": "glwquTVQHlo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Congratulations!** We've built a system that can do a good job at identifying articles that discuss clinical trials. You have built a classifier on a training set, tuned it with a validation set and finally evaluated it on a test set.\n",
        "\n",
        "We would now need to decide if the performance of the classifier is good enough to deploy. This will depend on the specific project and users of the system.\n",
        "\n",
        "Remember that for the clinical trials project, we aim to identify articles that the authors may have forgotten to tag as a clinical trial. Whether or not our system is suitable for deployment depends on how it will be used. For instance:\n",
        " - If we aim to automatically extend a database of clinical trials, we would want to be sure that the data that is inserted is very likely to be about a clinical trial. Otherwise, our database will become unreliable and reduce its utility. In this case, having a system that is high precision, say above 0.9 is desirable. Even if we miss some (i.e., have a lower recall), that might be alright because the alternative is missing these untagged articles anyway. But we'd still probably want reasonable recall (maybe > 0.5), otherwise it may not be worth the cost of deploying and maintaining the model.\n",
        " - If we instead aim to have a comprehensive list of clinical trial articles, high recall is critical. In this case, maybe we would target recall of at least 0.99, but acknowledge the fact that precision may suffer to achieve such recall. To counteract this, we would need to consider including a human in the loop to review the classified articles. To reduce human effort, we would want as high precision as possible while maintaining our target level of recall.\n",
        "\n",
        "For a trained model, these trade-offs can be made by adjusting the decision threshold. The [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or [precision-recall curve](https://www.geeksforgeeks.org/precision-recall-curve-ml/) may be helpful for this. You can explore this topic as an Optional Extra below."
      ],
      "metadata": {
        "id": "20W-b4FtEg-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End\n",
        "\n",
        "This is the end of Lab 4. Let us know if you encounter any issues! Remember we are here to help!\n",
        "\n",
        "**Please submit your lab through Moodle. We don't mark the labs but it helps us to craft better labs in the future**"
      ],
      "metadata": {
        "id": "eOZN3s-Vt-7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional Extras\n",
        "\n",
        "- The standard Spacy model is good for \"normal\" English but may not be the best for scientific English. There is a science-version of Spacy, known as [scispacy](https://allenai.github.io/scispacy/). Try out the `en_core_sci_sm` model from [scispacy](https://allenai.github.io/scispacy/). You'll need to install scispacy and the model.\n",
        "- See how only using the title performs\n",
        "- Try out other hyperparameters, such as bigrams from the vectorizer.\n",
        "- Construct and explore a [Receiver Operating Characteristic (ROC) curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) and [precision-recall curve](https://www.geeksforgeeks.org/precision-recall-curve-ml/) for your model, and think about their use for the two deployment settings discussed above. You'll need to get probabilities from your classifier and not just binary predictions. You'll want the `.predict_proba(...)` classifier function along with the [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) and [precision_recall_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html) functions. You then need to plot it. Here's some info on [line plotting with Matplotlib](https://jakevdp.github.io/PythonDataScienceHandbook/04.01-simple-line-plots.html).\n",
        "- If you're game for it, do the error analysis, look at some mistakenly misclassified documents and see if you can spot any patterns. If you do, let us know!"
      ],
      "metadata": {
        "id": "AdjwRHO2KLEm"
      }
    }
  ]
}